{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from dataset import DataloaderImg, GreyToRGB, NormalizeVolume\n",
    "from torch import optim\n",
    "import torchvision.transforms.v2 as tfms\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.ion()  # interactive mode\n",
    "\n",
    "# install pytorch correctly\n",
    "# https://discuss.pytorch.org/t/torch-cuda-is-not-available/74845/11\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    ")\n",
    "# install cuda driver ubuntu\n",
    "# https://ubuntu.com/server/docs/nvidia-drivers-installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/cuda.html\n",
    "# torch.cuda.is_initialized()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"Current cuda device: {torch.cuda.get_device_name(current_device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script for segmentation\n",
    "# https://github.com/mateuszbuda/brain-segmentation-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help in loading images\n",
    "# https://discuss.pytorch.org/t/how-to-load-all-the-nii-from-the-directory-without-augmentation-using-pytorch-dataloader/60938/3\n",
    "root_dir = \"/media/MeMoSLAP_Subjects/derivatives/automated_electrode_extraction\"  #!NOTE: delete \"/train\" for all subjects\n",
    "\n",
    "custom_transforms = [NormalizeVolume(), GreyToRGB()]\n",
    "transforms = [tfms.RandomRotation(180)]\n",
    "n_validation = 4\n",
    "# full_dataset = Dataloder_img('C:/Users/Ali ktk/.spyder-py3/dataloader/data/train/1', 'C:/Users/Ali ktk/.spyder-py3/dataloader/data/train/1/ADNI_136_S_0300_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20080529142830882_S50401_I107759.nii' ,tfms.Compose([tfms.RandomRotation(180).tfms.ToTensor()]))\n",
    "train_dataset = DataloaderImg(\n",
    "    root_dir,\n",
    "    subset=\"train\",\n",
    "    validation_cases=n_validation,\n",
    "    custom_transforms=custom_transforms,\n",
    "    transforms=transforms,\n",
    ")\n",
    "validation_dataset = DataloaderImg(\n",
    "    root_dir,\n",
    "    subset=\"validation\",\n",
    "    validation_cases=n_validation,\n",
    "    custom_transforms=custom_transforms,\n",
    "    transforms=transforms,\n",
    ")\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(img_batch, mask_batch, n_cols=3):\n",
    "    \"\"\"\n",
    "    Plot all images and masks of a batch as subplots with masks overlayed in red and opacity\n",
    "    \"\"\"\n",
    "\n",
    "    n_axs = n_img = len(img_batch)\n",
    "\n",
    "    if n_img % n_cols != 0:\n",
    "        n_axs += n_cols - (n_img % n_cols)\n",
    "\n",
    "    _, axs = plt.subplots(\n",
    "        int(n_axs / n_cols), n_cols, figsize=(15, 5 * int(n_axs / n_cols))\n",
    "    )\n",
    "\n",
    "    for img, mask, ax in zip(img_batch, mask_batch, axs.flatten()):\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "        ax.imshow(mask.squeeze(), alpha=0.3, cmap=\"Reds\")\n",
    "\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, train_mask = next(iter(loader))\n",
    "show_batch(train_img, train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = torch.hub.load(\n",
    "    \"mateuszbuda/brain-segmentation-pytorch\",\n",
    "    \"unet\",\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    init_features=32,\n",
    "    pretrained=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = 1.0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        if y_pred.size() != y_true.size():\n",
    "            raise ValueError(\"y_pred and y_true must have the same shape.\")\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2.0 * intersection + self.smooth) / (\n",
    "            y_pred.sum() + y_true.sum() + self.smooth\n",
    "        )\n",
    "        return 1.0 - dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(unet, input_size=(1, 3, 288, 288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.to(device)\n",
    "\n",
    "batch_size = 15  # todo: increase\n",
    "epochs = 1_000  # todo: increase\n",
    "vis_frequency = 10\n",
    "vis_images = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loaders = {\"train\": train_loader, \"valid\": valid_loader}\n",
    "\n",
    "dsc_loss = DiceLoss()\n",
    "best_validation_dsc = 0.0\n",
    "\n",
    "optimizer = optim.Adam(unet.parameters(), lr=1e-4)  # todo: whats lr?\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "step = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs), total=epochs):\n",
    "    # for phase in [\"train\", \"valid\"]:\n",
    "    # ...\n",
    "\n",
    "    phase = \"train\"\n",
    "\n",
    "    if phase == \"train\":\n",
    "        unet.train()\n",
    "    else:\n",
    "        unet.eval()\n",
    "\n",
    "    validation_pred = []\n",
    "    validation_true = []\n",
    "\n",
    "    for i, data in enumerate(loaders[phase]):\n",
    "        if phase == \"train\":\n",
    "            step += 1\n",
    "\n",
    "        x, y_true = data\n",
    "        x, y_true = x.to(device, dtype=torch.float), y_true.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "            y_pred = unet(x)\n",
    "            loss = dsc_loss(y_pred, y_true)\n",
    "\n",
    "            if phase == \"valid\":\n",
    "                loss_valid.append(loss.item())\n",
    "\n",
    "                y_pred_np = y_pred.detach().cpu().numpy()\n",
    "                validation_pred.extend(\n",
    "                    [y_pred_np[s] for s in range(y_pred_np.shape[0])]\n",
    "                )\n",
    "                y_true_np = y_true.detach().cpu().numpy()\n",
    "                validation_true.extend(\n",
    "                    [y_true_np[s] for s in range(y_true_np.shape[0])]\n",
    "                )\n",
    "\n",
    "                if (epochs % vis_frequency == 0) or (epoch == epochs - 1):\n",
    "                    if i * batch_size < vis_images:\n",
    "                        tag = f\"image/{i}\"\n",
    "                        num_images = vis_images - i * batch_size\n",
    "                        ...\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss_train.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        if phase == \"train\" and (step + 1) % 10 == 0:\n",
    "            ...\n",
    "\n",
    "    if phase == \"valid\":\n",
    "        ...\n",
    "\n",
    "print(\"Best validation mean DSC: {:.4f}\".format(best_validation_dsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.cpu().detach().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(unet, f\"unet_epochs_{epochs}_batchsize_{batch_size}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(x.cpu().detach().type(torch.IntTensor), y_pred.cpu().detach())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRI_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
