{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "#from skimage import transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "\n",
    "# install pytorch correctly \n",
    "# https://discuss.pytorch.org/t/torch-cuda-is-not-available/74845/11\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# install cuda driver ubuntu\n",
    "# https://ubuntu.com/server/docs/nvidia-drivers-installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://pytorch.org/docs/stable/cuda.html\n",
    "torch.cuda.is_initialized()\n",
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Please uninstall cpuonly in your conda environment. If torch.version.cuda returns none, then it means that you are using a CPU only binary. \n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script for segmentation\n",
    "#https://github.com/mateuszbuda/brain-segmentation-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help in loading images \n",
    "# https://discuss.pytorch.org/t/how-to-load-all-the-nii-from-the-directory-without-augmentation-using-pytorch-dataloader/60938/3\n",
    "root_dir = \"/media/MeMoSLAP_Subjects/derivatives/automated_electrode_extraction/train\"\n",
    "seg_dir = \"/media/MeMoSLAP_Subjects/derivatives/automated_electrode_extraction/train\"\n",
    "\n",
    "class Dataloder_img(Dataset):\n",
    "    def __init__(self,root_dir,transforms ):\n",
    "        self.root_dir = root_dir\n",
    "        self.seg_dir = seg_dir\n",
    "        self.transforms = transforms\n",
    "        self.files = os.listdir(self.root_dir)\n",
    "        self.lables = os.listdir(self.seg_dir)\n",
    "        print(self.files)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.files[idx]\n",
    "        label_name = self.lables[idx]\n",
    "        img = nib.load(os.path.join(self.root_dir,img_name)) \n",
    "        #change to numpy\n",
    "        img = np.array(img.dataobj)\n",
    "        #change to PIL \n",
    "#       img = Image.fromarray(img.astype('uint8'), 'RGB')    \n",
    "        print(img.size)\n",
    "        \n",
    "        label = nib.load(os.path.join(self.seg_dir,label_name))\n",
    "        #change to numpy\n",
    "        label = np.array(label.dataobj)\n",
    "        #change to PIL \n",
    "#       label = Image.fromarray(label.astype('uint8'), 'RGB')\n",
    "        \n",
    "        print(label.size)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "            label = self.transforms(label)\n",
    "            return img,label\n",
    "        else:\n",
    "            return img, label\n",
    "#full_dataset = Dataloder_img('C:/Users/Ali ktk/.spyder-py3/dataloader/data/train/1', 'C:/Users/Ali ktk/.spyder-py3/dataloader/data/train/1/ADNI_136_S_0300_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20080529142830882_S50401_I107759.nii' ,tfms.Compose([tfms.RandomRotation(180).tfms.ToTensor()]))\n",
    "full_dataset = Dataloder_img('/media/MeMoSLAP_Subjects/derivatives/automated_electrode_extraction/train', \n",
    "                             '/media/MeMoSLAP_Subjects/derivatives/automated_electrode_extraction/train' ,\n",
    "                             tfms.Compose([tfms.RandomRotation(180), tfms.ToTensor()]))\n",
    "                                   \n",
    "                                   \n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "train_loader = data.DataLoader(train_dataset,shuffle=False,batch_size=bs)\n",
    "val_loader = data.DataLoader(val_dataset,shuffle=False,batch_size=bs)\n",
    "\n",
    "test_img, test_lb = next(iter(full_dataset))\n",
    "print(test_img[0].shape)\n",
    "plt.imshow(test_img[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/media/MeMoSLAP_Subjects/derivatives/automated_electrode_extraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class BrainSegmentationDataset(Dataset):\n",
    "    \"\"\"Brain MRI dataset for FLAIR abnormality segmentation\"\"\"\n",
    "\n",
    "    in_channels = 3\n",
    "    out_channels = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir,\n",
    "        transform=None,\n",
    "        image_size=256,\n",
    "        subset=\"train\",\n",
    "        random_sampling=True,\n",
    "        validation_cases=40,\n",
    "        seed=42, #???\n",
    "    ):\n",
    "        assert subset in [\"all\", \"train\", \"validation\"]\n",
    "\n",
    "        # read images\n",
    "        volumes = {}\n",
    "        masks = {}\n",
    "        print(\"reading {} images...\".format(subset))\n",
    "        for (dirpath, dirnames, filenames) in os.walk(images_dir):\n",
    "            image_slices = []\n",
    "            mask_slices = []\n",
    "            for filename in sorted(\n",
    "                filter(lambda f: \".tif\" in f, filenames),\n",
    "                key=lambda x: int(x.split(\".\")[-2].split(\"_\")[4]),\n",
    "            ):\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                if \"mask\" in filename:\n",
    "                    mask_slices.append(imread(filepath, as_gray=True))\n",
    "                else:\n",
    "                    image_slices.append(imread(filepath))\n",
    "            if len(image_slices) > 0:\n",
    "                patient_id = dirpath.split(\"/\")[-1]\n",
    "                volumes[patient_id] = np.array(image_slices[1:-1])\n",
    "                masks[patient_id] = np.array(mask_slices[1:-1])\n",
    "\n",
    "        self.patients = sorted(volumes)\n",
    "\n",
    "        # select cases to subset\n",
    "        if not subset == \"all\":\n",
    "            random.seed(seed)\n",
    "            validation_patients = random.sample(self.patients, k=validation_cases)\n",
    "            if subset == \"validation\":\n",
    "                self.patients = validation_patients\n",
    "            else:\n",
    "                self.patients = sorted(\n",
    "                    list(set(self.patients).difference(validation_patients))\n",
    "                )\n",
    "\n",
    "        print(\"preprocessing {} volumes...\".format(subset))\n",
    "        # create list of tuples (volume, mask)\n",
    "        self.volumes = [(volumes[k], masks[k]) for k in self.patients]\n",
    "\n",
    "        print(\"cropping {} volumes...\".format(subset))\n",
    "        # crop to smallest enclosing volume\n",
    "        self.volumes = [crop_sample(v) for v in self.volumes]\n",
    "\n",
    "        print(\"padding {} volumes...\".format(subset))\n",
    "        # pad to square\n",
    "        self.volumes = [pad_sample(v) for v in self.volumes]\n",
    "\n",
    "        print(\"resizing {} volumes...\".format(subset))\n",
    "        # resize\n",
    "        self.volumes = [resize_sample(v, size=image_size) for v in self.volumes]\n",
    "\n",
    "        print(\"normalizing {} volumes...\".format(subset))\n",
    "        # normalize channel-wise\n",
    "        self.volumes = [(normalize_volume(v), m) for v, m in self.volumes]\n",
    "\n",
    "        # probabilities for sampling slices based on masks\n",
    "        self.slice_weights = [m.sum(axis=-1).sum(axis=-1) for v, m in self.volumes]\n",
    "        self.slice_weights = [\n",
    "            (s + (s.sum() * 0.1 / len(s))) / (s.sum() * 1.1) for s in self.slice_weights\n",
    "        ]\n",
    "\n",
    "        # add channel dimension to masks\n",
    "        self.volumes = [(v, m[..., np.newaxis]) for (v, m) in self.volumes]\n",
    "\n",
    "        print(\"done creating {} dataset\".format(subset))\n",
    "\n",
    "        # create global index for patient and slice (idx -> (p_idx, s_idx))\n",
    "        num_slices = [v.shape[0] for v, m in self.volumes]\n",
    "        self.patient_slice_index = list(\n",
    "            zip(\n",
    "                sum([[i] * num_slices[i] for i in range(len(num_slices))], []),\n",
    "                sum([list(range(x)) for x in num_slices], []),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.random_sampling = random_sampling\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_slice_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient = self.patient_slice_index[idx][0]\n",
    "        slice_n = self.patient_slice_index[idx][1]\n",
    "\n",
    "        if self.random_sampling:\n",
    "            patient = np.random.randint(len(self.volumes))\n",
    "            slice_n = np.random.choice(\n",
    "                range(self.volumes[patient][0].shape[0]), p=self.slice_weights[patient]\n",
    "            )\n",
    "\n",
    "        v, m = self.volumes[patient]\n",
    "        image = v[slice_n]\n",
    "        mask = m[slice_n]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image, mask = self.transform((image, mask))\n",
    "\n",
    "        # fix dimensions (C, H, W)\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        mask = mask.transpose(2, 0, 1)\n",
    "\n",
    "        image_tensor = torch.from_numpy(image.astype(np.float32))\n",
    "        mask_tensor = torch.from_numpy(mask.astype(np.float32))\n",
    "\n",
    "        # return tensors\n",
    "        return image_tensor, mask_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRI_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
